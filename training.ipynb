{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51cb31aa-3ab0-4359-b5ef-c0ed636c249e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61dc5faf-194d-4fae-8591-0d0073568ccc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP\\Desktop\\Resume Projects\\Python Projects\\ISL TPU Project\\training.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/Resume%20Projects/Python%20Projects/ISL%20TPU%20Project/training.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1200\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/Resume%20Projects/Python%20Projects/ISL%20TPU%20Project/training.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     image_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(char_folder, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mchar\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_processed.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/Resume%20Projects/Python%20Projects/ISL%20TPU%20Project/training.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/Resume%20Projects/Python%20Projects/ISL%20TPU%20Project/training.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)  \u001b[39m# Assuming images are grayscale\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Desktop/Resume%20Projects/Python%20Projects/ISL%20TPU%20Project/training.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(image, (\u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m))  \u001b[39m# Resize images to a consistent size\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up directories\n",
    "parent_dir = r\"C:\\Users\\HP\\Desktop\\Resume Projects\\Python Projects\\ISL TPU Project\\data\"\n",
    "output_dir = os.path.join(parent_dir, \"processed\")\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Resume Projects\\Python Projects\\ISL TPU Project\"\n",
    "# Load and preprocess the data\n",
    "data = []\n",
    "labels = []\n",
    "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
    "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
    "                   'Z':25}\n",
    "num_classes = 26\n",
    "\n",
    "# Iterate over each character folder\n",
    "for char in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "    char_folder = os.path.join(output_dir, char)\n",
    "\n",
    "    # Process each image for the character\n",
    "    for i in range(1200):\n",
    "        image_path = os.path.join(char_folder, f\"{char}_{i}_processed.jpg\")\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Assuming images are grayscale\n",
    "        image = cv2.resize(image, (64, 64))  # Resize images to a consistent size\n",
    "        data.append(image)\n",
    "        labels.append(labels_dict[char]) \n",
    "data = np.array(data)\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "data = data.astype(\"float32\") / 255.0\n",
    "labels = keras.utils.to_categorical(labels)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0be769-d6f0-433c-a72a-f31c02cb2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data, train_labels, test_labels) = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4580fcd0-0217-44f0-8d87-a4421869107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 61, 61, 64)        1088      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 29, 29, 64)        65600     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 29, 29, 64)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 26, 26, 128)       131200    \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 12, 12, 128)       262272    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 9, 9, 256)         524544    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 3, 3, 256)         1048832   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1180160   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 26)                13338     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3227034 (12.31 MB)\n",
      "Trainable params: 3227034 (12.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(128, kernel_size=4, strides=1, activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=4, strides=2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(256, kernel_size=4, strides=1, activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=4, strides=2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "model.summary()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e590503-0ddb-4b2e-8d2c-8d402fdb7623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "780/780 - 297s - loss: 0.2015 - accuracy: 0.9429 - 297s/epoch - 381ms/step\n",
      "Test accuracy: 0.9985576868057251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=2)\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "\n",
    "model_hist= model.fit(train_data, train_labels, epochs=1,batch_size=32,verbose=2)\n",
    "\n",
    "score = model.evaluate(x=test_data, y=test_labels,verbose=0)\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f864df-d202-4103-9864-5da379f589e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 17s 89ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Test Loss: 0.0047\n",
      "Test Accuracy: 99.86%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42b12b88-d097-4bd2-8e25-d8e645696ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"sign_recognition_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6253ae-0a18-405f-ba3c-0a7e6eec1e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
